{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qznORKN6eMxx"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aueES3y4fAae",
    "outputId": "7248a233-423c-40e6-cdac-f7e663def502"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7Q7DIUWfD4n"
   },
   "outputs": [],
   "source": [
    "raw_movie_docs = [\n",
    "    (movie_reviews.raw(fileid), category) for\n",
    "    category in movie_reviews.categories() for fileid in\n",
    "    movie_reviews.fileids(category)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0-tnRXYfT1Q"
   },
   "outputs": [],
   "source": [
    "random.seed(2920)\n",
    "random.shuffle(raw_movie_docs)\n",
    "movie_test = raw_movie_docs[:200]\n",
    "movie_dev = raw_movie_docs[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3LxfO1lg2sK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u88HcvrIfpHn"
   },
   "outputs": [],
   "source": [
    "train_data, dev_test_data = train_test_split(movie_dev, train_size=1600, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kskA-XLRhHXc"
   },
   "outputs": [],
   "source": [
    "train_texts = [t[0] for t in train_data]\n",
    "train_target = [t[1] for t in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORei5R9fhPKs"
   },
   "outputs": [],
   "source": [
    "dev_test_texts = [t[0] for t in dev_test_data]\n",
    "dev_test_target = [t[1] for t in dev_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UCSy0-4h7lw"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LubkUhmiGyK",
    "outputId": "b41b4d76-e43f-4df7-be25-35ba954ea6d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer()\n",
    "v.fit(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_EuRLSqiKI9"
   },
   "outputs": [],
   "source": [
    "train_vectors = v.transform(train_texts)\n",
    "dev_test_vectors = v.transform(dev_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpGQSgdAiOch",
    "outputId": "ba824d34-8bf1-4e86-d4b1-d9b171667543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_vectors, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OUabrnriS8x",
    "outputId": "6641d721-59a2-49f9-b770-01c2d26313b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg'], dtype='<U3')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_test_texts[14]\n",
    "clf.predict(dev_test_vectors[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpwUcC9-iV_f",
    "outputId": "95b4d8a1-563e-4fb5-cf8f-54a33cd75791"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'pos', 'neg', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos',\n",
       "       'neg', 'pos', 'neg', 'neg', 'pos', 'neg', 'neg', 'pos', 'neg',\n",
       "       'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos', 'pos', 'neg',\n",
       "       'neg', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'neg',\n",
       "       'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg',\n",
       "       'pos', 'pos', 'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'neg',\n",
       "       'pos', 'pos', 'neg', 'neg', 'pos', 'neg', 'neg', 'pos', 'pos',\n",
       "       'neg', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos', 'pos',\n",
       "       'neg', 'neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos',\n",
       "       'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg', 'neg', 'pos',\n",
       "       'neg', 'neg', 'pos', 'neg', 'neg', 'pos', 'pos', 'neg', 'pos',\n",
       "       'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'pos',\n",
       "       'pos', 'pos', 'pos', 'neg', 'neg', 'pos', 'neg', 'pos', 'pos',\n",
       "       'neg', 'neg', 'pos', 'pos', 'pos', 'pos', 'neg', 'pos', 'pos',\n",
       "       'pos', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg',\n",
       "       'neg', 'pos', 'neg', 'pos', 'pos', 'neg', 'pos', 'pos', 'pos',\n",
       "       'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos',\n",
       "       'pos', 'neg', 'neg', 'neg', 'pos', 'pos', 'pos', 'neg', 'neg',\n",
       "       'neg', 'neg', 'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'neg',\n",
       "       'neg', 'pos', 'neg', 'pos', 'pos', 'pos', 'neg', 'pos', 'neg',\n",
       "       'pos', 'pos', 'pos', 'pos', 'pos', 'neg', 'neg', 'neg', 'neg',\n",
       "       'pos', 'pos', 'neg', 'pos', 'neg', 'pos', 'pos', 'neg', 'neg',\n",
       "       'pos', 'pos'], dtype='<U3')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(dev_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeDAzPNLiZOU",
    "outputId": "8104b723-4fb6-4b41-c4ce-a121ef168132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(dev_test_vectors, dev_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSbi0P4KiiI-"
   },
   "source": [
    "### 1.1.2 1b) Parameters of the vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9ozytqRjQtO"
   },
   "source": [
    "Run experiments where you let binary vary over [False, True] and ngram_range vary over [[1,1],\n",
    "[1,2], [1,3]] and report the accuracy with the 6 different settings in a 2x3 table.\n",
    "Which settings yield the best results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHg5yRDzifG2",
    "outputId": "4de843fe-9158-4872-a7e6-8911ec0d1a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary = True; Ngram_range = [1, 1] -> score = 0.81\n",
      "Binary = True; Ngram_range = [1, 2] -> score = 0.84\n",
      "Binary = True; Ngram_range = [1, 3] -> score = 0.855\n",
      "Binary = False; Ngram_range = [1, 1] -> score = 0.82\n",
      "Binary = False; Ngram_range = [1, 2] -> score = 0.83\n",
      "Binary = False; Ngram_range = [1, 3] -> score = 0.8\n"
     ]
    }
   ],
   "source": [
    "binary_param = [True, False]\n",
    "ngram_range_param = [[1,1], [1,2], [1,3]]\n",
    "\n",
    "for bp in binary_param:\n",
    "  for ngram_param in ngram_range_param:\n",
    "    v = CountVectorizer(\n",
    "        binary=bp,\n",
    "        ngram_range=ngram_param\n",
    "    )\n",
    "    train_vec = v.fit_transform(train_texts)\n",
    "    dev_test_vec = v.transform(dev_test_texts)\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(train_vec, train_target)\n",
    "    score = clf.score(dev_test_vec, dev_test_target)\n",
    "\n",
    "    print(f\"Binary = {bp}; Ngram_range = {ngram_param} -> score = {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSmxPuJ7L6mR"
   },
   "source": [
    "Binary = Ture and n_gram_range = [1,3] yields the best result of 0.855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwP2VUOGlW6f"
   },
   "source": [
    "### 1.2 Ex 2 n-fold cross-validation (12 points)\n",
    "#### 1.2.1 2a)\n",
    "\n",
    "Our dev_test_data contains only 200 items. That is a small number for a test set for a binary\n",
    "classifier. The numbers we report may depend to a large degree on the split between training\n",
    "and test data. To get more reliable numbers, we may use n-gram cross-validation. We can use\n",
    "the whole dev_test_data of 1800 items for this. To get round numbers, we decide to use 9-fold\n",
    "cross-validation, which will put 200 items in each test set.\n",
    "Use the best settings from exercise 1 and run a 9-fold cross-validation. Report the accuracy for\n",
    "each run, together with the mean and standard deviation of the 9 runs.\n",
    "In this exercise, you are requested to implement the routine for cross-validation yourself, and not\n",
    "apply the scikit-learn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHzatn66mLK1"
   },
   "outputs": [],
   "source": [
    "cv_train_texts = [t[0] for t in movie_dev]\n",
    "cv_train_target = [t[1] for t in movie_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7Hx5P-ek-Xc"
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "increment = 200\n",
    "scores = []\n",
    "\n",
    "v = CountVectorizer(\n",
    "    binary=True,\n",
    "    ngram_range=[1,3]\n",
    ")\n",
    "\n",
    "for cv in range(9):\n",
    "  val_txt = cv_train_texts[idx:idx+increment]\n",
    "  val_target = cv_train_target[idx:idx+increment]\n",
    "\n",
    "  train_txt = cv_train_texts[:idx] + cv_train_texts[idx+increment:]\n",
    "  train_target = cv_train_target[:idx] + cv_train_target[idx+increment:]\n",
    "\n",
    "  idx += increment\n",
    "\n",
    "  train_vec = v.fit_transform(train_txt)\n",
    "  val_vec = v.transform(val_txt)\n",
    "\n",
    "  clf = MultinomialNB()\n",
    "  clf.fit(train_vec, train_target)\n",
    "  score = clf.score(val_vec, val_target)\n",
    "  scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkRHmwM4n7PT",
    "outputId": "a17728a2-0140-43d7-9c3c-33bbfbf146e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.815, 0.855, 0.87, 0.85, 0.82, 0.855, 0.89, 0.84, 0.86]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores for run 1 too run 9\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2ytoe1KpBHJ",
    "outputId": "45ae666c-68cd-4a22-ee98-5971137cfd99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505555555555556"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean score of the 9 runs\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYzCYjYVpFrU",
    "outputId": "746f8bb3-3c67-4220-f442-a446b2950731"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022040927138752657"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard deviation for the 9 runs\n",
    "np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1EdEq4JlWcP"
   },
   "source": [
    "#### 1.2.2 2b)\n",
    "The large variation we see between the results, raises a question regarding whether the optimal\n",
    "settings we found in exercise 1, would also be optimal for another split between training and test.\n",
    "To find out, we combine the 9-fold cross-validation with the various settings for CountVectorizer.\n",
    "For each of the 6 settings, run 9-fold cross-validation and calculate the mean accuracy. Report the\n",
    "results in a 2x3 table. Answer: Do you see the same as when you only used one test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vGBoWZfpe49"
   },
   "outputs": [],
   "source": [
    "def cv(iters, val_size, param_binary, param_ngram_range, clf_to_fit):\n",
    "  idx = 0\n",
    "  increment = val_size\n",
    "  scores = []\n",
    "\n",
    "  v = CountVectorizer(\n",
    "      binary=param_binary,\n",
    "      ngram_range=param_ngram_range\n",
    "  )\n",
    "\n",
    "  for cv in range(iters):\n",
    "    val_txt = cv_train_texts[idx:idx+increment]\n",
    "    val_target = cv_train_target[idx:idx+increment]\n",
    "\n",
    "    train_txt = cv_train_texts[:idx] + cv_train_texts[idx+increment:]\n",
    "    train_target = cv_train_target[:idx] + cv_train_target[idx+increment:]\n",
    "\n",
    "    idx += increment\n",
    "\n",
    "    train_vec = v.fit_transform(train_txt)\n",
    "    val_vec = v.transform(val_txt)\n",
    "\n",
    "    clf = clf_to_fit()\n",
    "    clf.fit(train_vec, train_target)\n",
    "    score = clf.score(val_vec, val_target)\n",
    "    scores.append(score)\n",
    "\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xAhXJKPqNWV",
    "outputId": "df64ac21-3356-4790-a5cc-81fbd706ae39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary = True; Ngram_range = [1, 1] \n",
      "        -> Mean score = 0.8216666666666668 \n",
      "        -> std = 0.021343747458109467\n",
      "Binary = True; Ngram_range = [1, 2] \n",
      "        -> Mean score = 0.8533333333333333 \n",
      "        -> std = 0.02818589087547963\n",
      "Binary = True; Ngram_range = [1, 3] \n",
      "        -> Mean score = 0.8505555555555556 \n",
      "        -> std = 0.022040927138752657\n",
      "Binary = False; Ngram_range = [1, 1] \n",
      "        -> Mean score = 0.8172222222222223 \n",
      "        -> std = 0.02517837598583255\n",
      "Binary = False; Ngram_range = [1, 2] \n",
      "        -> Mean score = 0.833888888888889 \n",
      "        -> std = 0.019547346761954645\n",
      "Binary = False; Ngram_range = [1, 3] \n",
      "        -> Mean score = 0.8188888888888889 \n",
      "        -> std = 0.0183753726761569\n"
     ]
    }
   ],
   "source": [
    "binary_param = [True, False]\n",
    "ngram_range_param = [[1,1], [1,2], [1,3]]\n",
    "\n",
    "for bp in binary_param:\n",
    "  for ngram_param in ngram_range_param:\n",
    "    scores = cv(9, 200, bp, ngram_param, MultinomialNB )\n",
    "\n",
    "    print(f\"\"\"Binary = {bp}; Ngram_range = {ngram_param} \n",
    "        -> Mean score = {np.mean(scores)} \n",
    "        -> std = {np.std(scores)}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTN19wbGMp13"
   },
   "source": [
    "The best parameters has changed from binary = True & n_gram_range = [1,3] too binary = True & n_gram_range = [1,2]. I would say the results are about the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDxjdWhQrxi1"
   },
   "source": [
    "### 1.3 Ex 3 Logistic Regression (8 points)\n",
    "We know that Logistic Regression may produce better results than Naive Bayes. We will see what\n",
    "happens if we use Logistic Regression instead of Naive Bayes on this task. We start with the\n",
    "same multinomial model for text classification as in exercises (1) and (2) above (i.e. we process\n",
    "the data the same way and use the same vectorizer), but exchange the learner with sciki-learn’s\n",
    "LogisticRegression. Since logistic regression is slow to train, we restrict ourselves somewhat with\n",
    "respect to which experiments to run. We consider two settings for the CountVectorizer, the default\n",
    "setting and the setting which gave the best result with naive Bayes when we ran cross-validation.\n",
    "(Though, this does not have to be the best setting for the logistic regression). For each of the two\n",
    "settings, run 9-fold cross-validation and calculate the mean accuracy. Compare the results in a 2x2\n",
    "table where one axis is Naive Bayes vs. Logistic Regression and the other axis is default settings\n",
    "vs. earlier best settings for CountVectorizer. Write a few sentences where you discuss what you see\n",
    "from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOq9KZW8qwYv",
    "outputId": "54b87a5e-fe74-4d17-9617-48a03643153c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary = False; Ngram_range = [1, 1] \n",
      "        -> Mean score = 0.8355555555555555 \n",
      "        -> std = 0.01770819716723247\n",
      "Binary = True; Ngram_range = [1, 2] \n",
      "        -> Mean score = 0.8733333333333333 \n",
      "        -> std = 0.014337208778404392\n"
     ]
    }
   ],
   "source": [
    "# default: binary = False, ngram_range = [1,1]\n",
    "# best params for multinomial: binary = True, ngram_range=[1,2]\n",
    "# [(binary, ngram_range)]\n",
    "params = [\n",
    "    (False, [1,1]), \n",
    "    (True, [1,2])\n",
    "]\n",
    "\n",
    "for param_combo in params:\n",
    "    scores = cv(9, 200, param_combo[0], param_combo[1], LogisticRegression)\n",
    "\n",
    "    print(f\"\"\"Binary = {param_combo[0]}; Ngram_range = {param_combo[1]} \n",
    "        -> Mean score = {np.mean(scores)} \n",
    "        -> std = {np.std(scores)}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sgp3uhjgNXAk"
   },
   "source": [
    "Params | Logit | Naive-bayes\n",
    "--- | :---: | :---:\n",
    "`default` | `0.84` | `0.82`\n",
    "`best params` | `0.87` | `0.85`\n",
    "\n",
    "\n",
    "We se that logit does a better job at predicting than naive-bayes, this is true for defaults parameters and the best parameters. This comes at higher computational costs. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
